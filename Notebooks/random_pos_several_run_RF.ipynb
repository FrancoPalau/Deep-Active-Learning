{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_position_string(x):\n",
    "    maxlen = 10\n",
    "    if len(x)<=maxlen:\n",
    "        return x\n",
    "    else:\n",
    "        rand_pos = randint(0,len(x)-maxlen)\n",
    "        return x[rand_pos:rand_pos+maxlen]\n",
    "    \n",
    "def change_class(x):\n",
    "    if x == \"botnet\":\n",
    "        return 1\n",
    "    elif x== \"normal\":\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 708  127]\n",
      " [ 146 1739]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       835\n",
      "           1       0.93      0.92      0.93      1885\n",
      "\n",
      "    accuracy                           0.90      2720\n",
      "   macro avg       0.88      0.89      0.88      2720\n",
      "weighted avg       0.90      0.90      0.90      2720\n",
      "\n",
      "[[ 701  146]\n",
      " [ 148 1725]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       847\n",
      "           1       0.92      0.92      0.92      1873\n",
      "\n",
      "    accuracy                           0.89      2720\n",
      "   macro avg       0.87      0.87      0.87      2720\n",
      "weighted avg       0.89      0.89      0.89      2720\n",
      "\n",
      "[[ 689  142]\n",
      " [ 157 1732]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       831\n",
      "           1       0.92      0.92      0.92      1889\n",
      "\n",
      "    accuracy                           0.89      2720\n",
      "   macro avg       0.87      0.87      0.87      2720\n",
      "weighted avg       0.89      0.89      0.89      2720\n",
      "\n",
      "[[ 699  132]\n",
      " [ 148 1741]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83       831\n",
      "           1       0.93      0.92      0.93      1889\n",
      "\n",
      "    accuracy                           0.90      2720\n",
      "   macro avg       0.88      0.88      0.88      2720\n",
      "weighted avg       0.90      0.90      0.90      2720\n",
      "\n",
      "[[ 712  127]\n",
      " [ 153 1728]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84       839\n",
      "           1       0.93      0.92      0.93      1881\n",
      "\n",
      "    accuracy                           0.90      2720\n",
      "   macro avg       0.88      0.88      0.88      2720\n",
      "weighted avg       0.90      0.90      0.90      2720\n",
      "\n",
      "[[ 717  137]\n",
      " [ 133 1733]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       854\n",
      "           1       0.93      0.93      0.93      1866\n",
      "\n",
      "    accuracy                           0.90      2720\n",
      "   macro avg       0.89      0.88      0.88      2720\n",
      "weighted avg       0.90      0.90      0.90      2720\n",
      "\n",
      "[[ 704  164]\n",
      " [ 106 1746]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84       868\n",
      "           1       0.91      0.94      0.93      1852\n",
      "\n",
      "    accuracy                           0.90      2720\n",
      "   macro avg       0.89      0.88      0.88      2720\n",
      "weighted avg       0.90      0.90      0.90      2720\n",
      "\n",
      "[[ 666  135]\n",
      " [ 147 1772]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83       801\n",
      "           1       0.93      0.92      0.93      1919\n",
      "\n",
      "    accuracy                           0.90      2720\n",
      "   macro avg       0.87      0.88      0.88      2720\n",
      "weighted avg       0.90      0.90      0.90      2720\n",
      "\n",
      "[[ 731  134]\n",
      " [ 140 1715]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84       865\n",
      "           1       0.93      0.92      0.93      1855\n",
      "\n",
      "    accuracy                           0.90      2720\n",
      "   macro avg       0.88      0.88      0.88      2720\n",
      "weighted avg       0.90      0.90      0.90      2720\n",
      "\n",
      "[[ 699  127]\n",
      " [ 165 1729]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       826\n",
      "           1       0.93      0.91      0.92      1894\n",
      "\n",
      "    accuracy                           0.89      2720\n",
      "   macro avg       0.87      0.88      0.87      2720\n",
      "weighted avg       0.89      0.89      0.89      2720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    #Read raw dataset\n",
    "    ctu_13 = pd.read_csv(\"../Datasets/ctu-13.labeled.cleaned.csv\")\n",
    "    \n",
    "    #remove first 4 charc.\n",
    "    ctu_13[\"State\"] = ctu_13[\"State\"].apply(lambda x: x[3:])\n",
    "    \n",
    "    #Select sub-string from random pos\n",
    "    ctu_13[\"State\"] = ctu_13[\"State\"].apply(random_position_string)\n",
    "    \n",
    "    #FEATURE VECTOR\n",
    "    #Periodicity\n",
    "    ctu_13[\"strong_p\"] = ctu_13[\"State\"].str.count('[a-i]')\n",
    "    ctu_13[\"weak_p\"] = ctu_13[\"State\"].str.count('[A-I]')\n",
    "    ctu_13[\"weak_np\"] = ctu_13[\"State\"].str.count('[r-z]')\n",
    "    ctu_13[\"strong_np\"] = ctu_13[\"State\"].str.count('[R-Z]')\n",
    "    #Duration\n",
    "    ctu_13[\"duration_s\"] = ctu_13[\"State\"].str.count('(a|A|r|R|1|d|D|u|U|4|g|G|x|X|7)')\n",
    "    ctu_13[\"duration_m\"] = ctu_13[\"State\"].str.count('(b|B|s|S|2|e|E|v|V|5|h|H|y|Y|8)')\n",
    "    ctu_13[\"duration_l\"] = ctu_13[\"State\"].str.count('(c|C|t|T|3|f|F|w|W|6|i|I|z|Z|9)')\n",
    "    #Size\n",
    "    ctu_13[\"size_s\"] = ctu_13[\"State\"].str.count('[a-c]') + \\\n",
    "                        ctu_13[\"State\"].str.count('[A-C]') + \\\n",
    "                        ctu_13[\"State\"].str.count('[r-t]') + \\\n",
    "                        ctu_13[\"State\"].str.count('[R-T]') + \\\n",
    "                        ctu_13[\"State\"].str.count('[1-3]')\n",
    "    ctu_13[\"size_m\"] = ctu_13[\"State\"].str.count('[d-f]') + \\\n",
    "                        ctu_13[\"State\"].str.count('[D-F]') + \\\n",
    "                        ctu_13[\"State\"].str.count('[u-w]') + \\\n",
    "                        ctu_13[\"State\"].str.count('[U-W]') + \\\n",
    "                        ctu_13[\"State\"].str.count('[4-6]')\n",
    "    ctu_13[\"size_l\"] = ctu_13[\"State\"].str.count('[g-i]') + \\\n",
    "                        ctu_13[\"State\"].str.count('[G-I]') + \\\n",
    "                        ctu_13[\"State\"].str.count('[x-z]') + \\\n",
    "                        ctu_13[\"State\"].str.count('[X-Z]') + \\\n",
    "                        ctu_13[\"State\"].str.count('[7-9]')\n",
    "    #Periodicity %\n",
    "    ctu_13[\"strong_p\"] = ctu_13[\"strong_p\"]/ctu_13[\"modelsize\"]\n",
    "    ctu_13[\"weak_p\"] = ctu_13[\"weak_p\"]/ctu_13[\"modelsize\"]\n",
    "    ctu_13[\"strong_np\"] = ctu_13[\"strong_np\"]/ctu_13[\"modelsize\"]\n",
    "    ctu_13[\"weak_np\"] = ctu_13[\"weak_np\"]/ctu_13[\"modelsize\"]\n",
    "    #Duration %\n",
    "    ctu_13[\"duration_s\"] = ctu_13[\"duration_s\"]/ctu_13[\"modelsize\"]\n",
    "    ctu_13[\"duration_m\"] = ctu_13[\"duration_m\"]/ctu_13[\"modelsize\"]\n",
    "    ctu_13[\"duration_l\"] = ctu_13[\"duration_l\"]/ctu_13[\"modelsize\"]\n",
    "    #Size %\n",
    "    ctu_13[\"size_s\"] = ctu_13[\"size_s\"]/ctu_13[\"modelsize\"]\n",
    "    ctu_13[\"size_m\"] = ctu_13[\"size_m\"]/ctu_13[\"modelsize\"]\n",
    "    ctu_13[\"size_l\"] = ctu_13[\"size_l\"]/ctu_13[\"modelsize\"]\n",
    "    \n",
    "    #clean dataset\n",
    "    ctu_13[\"class\"] = ctu_13[\"class\"].apply(change_class)\n",
    "    ctu_13.drop([\"src\",\"dst\",\"port\",\"proto\",\"label\",\"modelsize\",\"State\"], axis=1, inplace=True)\n",
    "    ctu_13.dropna(inplace=True)\n",
    "    \n",
    "    #Divide train-test dataset\n",
    "    x = ctu_13.drop('class',axis=1)\n",
    "    y = ctu_13['class']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "    \n",
    "    #Training\n",
    "    rfc = RandomForestClassifier(n_estimators=100)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    \n",
    "    #Testing\n",
    "    rfc_pred = rfc.predict(X_test)\n",
    "    print(confusion_matrix(y_test,rfc_pred))\n",
    "    print(classification_report(y_test,rfc_pred))\n",
    "    \n",
    "    report = classification_report(y_test,rfc_pred,\n",
    "            target_names=[\"normal\",\"botnet\"], digits=4, output_dict=True)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    #df.iloc[[0,1]].to_csv(\"../Datasets/test_rf.csv\",index=False, mode=\"a\", header=False)\n",
    "    #name = \"../Datasets/Random_pos/ctu_13_without_first_5_charc_and_rand_pos_maxlen75_run\"+\"i\"+\".csv\"\n",
    "    #ctu_13.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3cb74a76d5e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../Datasets/test_rf_75_Harpo.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
